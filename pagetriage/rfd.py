"""Functions for detecting and patrolling RfD'd pages.

When a redirect is nominated for discussion at RfD, it is placed in the
articles queue of Special:NewPagesFeed.  These functions identify such
"articles", double-check that they've been filed to RfD, and, if so,
patrol them.  After 30 minutes of not being filed to RfD, a page is
logged as such on-wiki.
"""
import datetime as dt
from enum import Enum
import re
from typing import Literal, Union

from mwclient.page import Page  # type:ignore[import-untyped]
import mwparserfromhell as mwph  # type:ignore[import-untyped]
from mwparserfromhell.nodes import Heading, Tag  # type:ignore[import-untyped]

import client
from client import PageNotFoundError
from classes import Namespace, SensitiveList, Title
import logging_
from logging_ import OnWikiLogger

FiledCheck = Union[Literal[False], list[Tag]]
# This is only guaranteed to match the output of {{subst:rfd}}.  If for
# some reason someone manually added the subst'd output and changed with
# the spacing, it would not read as a match.  This can be changed if
# there's anyone out there actually doing that.
#
# Note that this does not check wikilink validity, since an invalidly-
# formulated link could still potentially land at RfD (although it would
# probably be speedily resolved).
# pylint: disable=line-too-long
_TAGGED = re.compile(
    r"""\{\{NOINDEX\}\}\{\{<includeonly>safesubst:</includeonly>\#invoke:RfD(\|.*?){3}month = \w+
\|day = [ \d]\d
\|year = \d{4}
\|time = \d{2}:\d{2}
\|timestamp = \d{14}
<!-- .* -->
<!-- .* -->\|content=
\#[Rr][Ee][Dd][Ii][Rr][Ee][Cc][Tt] *\[\[.+?\]\]"""
)
_DEPRECATED = re.compile(
    '<!-- Do not use the "Rfd-NPF/core" template directly; the above line is '
    r'generated by \{\{subst:Rfd-NPF\}\}\. -->'
)
_onwiki_logger = OnWikiLogger("skippedRfDs.json")


class _Messages(Enum):
    RFD0 = "[[{page}]] not filed to [[{rfd}]] (currently a redlink)."
    RFD1 = "[[{page}]] not filed to [[{rfd}]]."
    RFD2 = ("[[{page}]] filed to [[{rfd}]], but that log page has "
            "not been transcluded to main RfD page.")
    RFD3 = "{{{{Rfd-NPF}}}}, not currently supported."


def _check_regexes(page: Page) -> bool:
    """Check if a page matches RfD-related regexes.

    If tagged with `_DEPRECATED`, logs as a skipped RfD.

    Arg:
      page:  A Page corresponding to a wikipage tagged with
        {{subst:rfd}}.

    Returns:
      A bool of whether the page is tagged with `_TAGGED`.
    """
    if _TAGGED.match(page.text()):
        return True
    if _DEPRECATED.search(page.text()):
        page_title = Title.from_page(page)
        print(f"{page_title} is deprecated")
        _onwiki_logger.log(_Messages.RFD3, page_title)
    return False


def _check_filed(page: Page) -> FiledCheck:
    """Check an RfD log page for an anchor matching the page's title.

    {{subst:rfd2}} makes such anchors automatically.  As with TAGGED, no
    guarantee of matching markup that renders the same way but is
    generated through some other means.

    Arg:
      page:  A Page corresponding to a wikipage tagged with
        {{subst:rfd}}.

    Returns:
      A bool indicating whether an RfD entry exists matching the page's
      title.
    """
    rfd_title = _extract_rfd(page)
    page_title = Title.from_page(page)
    try:
        rfd = client.get_page(title=rfd_title.pagename,
                           ns=rfd_title.namespace,
                           must_exist=True)
    except PageNotFoundError:
        print(f"No RfD page for {page_title}.")
        logging_.log_local(page_title, "no_rfd_logpage.txt")
        _onwiki_logger.log(_Messages.RFD0, page_title, rfd=rfd_title)
        return False

    # What idiot made this line necessary by building quotation-mark escaping
    # into {{rfd2}}?  Oh right.  Me.
    anchor = page_title.replace('"', "&quot;").removeprefix(":")
    parsed = mwph.parse(rfd.text())
    filed: list[Tag] | list[Heading] = (
        parsed.filter_headings(
            matches=lambda heading: _compress_ws(heading.title) == anchor
        )
        or parsed.filter_tags(
            matches=lambda tag: _is_correct_anchor(tag, anchor)
        )
    )
    transcluders = [i.name for i in rfd.embeddedin()]

    if not filed:
        print(f"RfD not filed for {page_title}.")
        logging_.log_local(page_title, "rfd_not_filed.txt")
        if dt.datetime.now() - page.editTime() > dt.timedelta(minutes=30):
            _onwiki_logger.log(_Messages.RFD1, page_title, rfd=rfd_title)
    elif "Wikipedia:Redirects for discussion" not in transcluders:
        print(f"{rfd_title} not transcluded to main RfD page.")
        logging_.log_local(page_title, "rfd_log_not_transcluded.txt")
        _onwiki_logger.log(_Messages.RFD2, page_title, rfd=rfd_title)
        return False
    return filed


def _extract_rfd(page: Page) -> Title:
    """Get the title of the log page referenced by an RfD tag.

    Uses the standard RfD log format and the `year`, `month`, and `day`
    parameters in {{subst:rfd}}.  This accounts for RfDs filed to
    previous dates.

    Arg:
      page:  A Page corresponding to a wikipage tagged with
        {{subst:rfd}}.

    Returns:
      A Title for an RfD log page, without guarantee that the page exists.
    """
    # Ugly hack around <https://github.com/earwig/mwparserfromhell/issues/251>.
    text = page.text().replace("<includeonly>safesubst:</includeonly>", "")
    parsed = mwph.parse(text)
    template = parsed.filter_templates()[1]
    year, month, day = (template.get(s).value.strip()
                        for s in ("year", "month", "day"))
    return Title(Namespace.PROJECT,
                 f"Redirects for discussion/Log/{year} {month} {day}")


def _is_correct_anchor(tag: Tag, target: str) -> bool:
    if tag.tag != 'span':
        return False
    try:
        # `strip('"')` could obscure HTML errors
        id_ = (tag.get('id').split("=", maxsplit=1)[1]
               .removeprefix('"').removesuffix('"'))
    except ValueError:  # If span has no id.
        return False
    return _compress_ws(id_) == target


def _compress_ws(text: str) -> str:
    return " ".join(text.split())


def check_rfd(page: Page) -> bool | FiledCheck:
    """Check if a page is subject to an ongoing RfD.

    First checks for the {{subst:rfd}} tag, then for whether there's an
    entry at the corresponding RfD log page.

    Arg:
      page:  A Page corresponding to a wikipage to be checked.

    Returns:
      A bool, True if both TAGGED matches and checkfiled() returns True.
      (If the former but not the latter, the distinction is made clear
      by logs.)
    """
    return _check_regexes(page) and _check_filed(page)


def cleanup(unreviewed_titles: list[str]) -> None:
    """Remove old and resolved log entries.

    Returns:
      A bool indicating whether cleanup occurred.
    """
    with _onwiki_logger.edit("Removing old and/or reviewed entries.") as data:
        for day, entries in data.copy().items():
            if _onwiki_logger.day_too_old(day):
                del data[day]
            else:
                entries = SensitiveList(
                    [i for i in entries
                     if i['page'].removeprefix(":") in unreviewed_titles]
                )
                if not entries:
                    del data[day]
                else:
                    data[day] = entries
        if data.been_changed():
            print("Cleaning up skippedRfDs.json")
