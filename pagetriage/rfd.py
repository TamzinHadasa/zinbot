"""Functions for detecting and patrolling RfD'd pages.

When a redirect is nominated for discussion at RfD, it is placed in the
articles queue of Special:NewPagesFeed.  These functions identify such
"articles", double-check that they've been filed to RfD, and, if so,
patrol them.  After 30 minutes of not being filed to RfD, a page is
logged as such on-wiki.
"""
import datetime as dt
from enum import Enum
import re
from typing import Literal, Union

import mwparserfromhell as mwph
from mwparserfromhell.nodes import Heading, Tag
from pywikibot import Page

import api
from api import PageNotFoundError
from classes import Namespace, SensitiveList, Title
import logging_
from logging_ import OnWikiLogger

from typing import Union

FiledCheck = Union[Literal[False], list[Tag]]
# This is only guaranteed to match the output of {{subst:rfd}}.  If for
# some reason someone manually added the subst'd output and changed with
# the spacing, it would not read as a match.  This can be changed if
# there's anyone out there actually doing that.
#
# Note that this does not check wikilink validity, since an invalidly-
# formulated link could still potentially land at RfD (although it would
# probably be speedily resolved).
# pylint: disable=line-too-long
_TAGGED = re.compile(
    r"""\{\{<includeonly>safesubst:</includeonly>\#invoke:RfD(\|.*?){3}month = \w+
\|day = [ \d]\d
\|year = \d{4}
\|time = \d{2}:\d{2}
\|timestamp = \d{14}
<!-- .* -->
<!-- .* -->\|content=
\#[Rr][Ee][Dd][Ii][Rr][Ee][Cc][Tt] *\[\[.+?\]\]"""
)
_DEPRECATED = re.compile(
    '<!-- Do not use the "Rfd-NPF/core" template directly; the above line is '
    r'generated by \{\{subst:Rfd-NPF\}\}\. -->'
)
_onwiki_logger = OnWikiLogger("skippedRfDs.json")


class _Messages(Enum):
    RFD0 = "[[{page}]] not filed to [[{rfd}]] (currently a redlink)."
    RFD1 = "[[{page}]] not filed to [[{rfd}]]."
    RFD2 = ("[[{page}]] filed to [[{rfd}]], but that log page has "
            "not been transcluded to main RfD page.")
    RFD3 = "[[{page}]] tagged with {{{{Rfd-NPF/core}}}} directly."


def check_rfd(page: Page) -> Union[bool, FiledCheck]:
    """Check if a page is subject to an ongoing RfD.

    First checks for the {{subst:rfd}} tag, then for whether there's an
    entry at the corresponding RfD log page.

    Arg:
      page:  A Page corresponding to a wikipage to be checked.

    Returns:
      A bool, True if both TAGGED matches and checkfiled() returns True.
      (If the former but not the latter, the distinction is made clear
      by logs.)
    """
    return _check_regexes(page) and _check_filed(page)


def _check_regexes(page: Page) -> bool:
    """Check if a page matches RfD-related regexes.

    If tagged with `_DEPRECATED`, logs as a skipped RfD.

    Arg:
      page:  A Page corresponding to a wikipage tagged with
        {{subst:rfd}}.

    Returns:
      A bool of whether the page is tagged with `_TAGGED`.
    """
    if _TAGGED.match(page.text):
        return True
    if _DEPRECATED.search(page.text):
        page_title = Title.from_page(page)
        print(f"{page_title} is deprecated")
        _onwiki_logger.log(_Messages.RFD3, page_title, api.site_time())
    return False


def _check_filed(page: Page) -> FiledCheck:
    """Check an RfD log page for an anchor matching the page's title.

    {{subst:rfd2}} makes such anchors automatically.  As with TAGGED, no
    guarantee of matching markup that renders the same way but is
    generated through some other means.

    Arg:
      page:  A Page corresponding to a wikipage tagged with
        {{subst:rfd}}.

    Returns:
      A bool indicating whether an RfD entry exists matching the page's
      title.
    """
    now = api.site_time()
    rfd_title = _extract_rfd(page)
    page_title = Title.from_page(page)
    try:
        rfd = api.get_page(title=rfd_title.pagename,
                           ns=rfd_title.namespace,
                           must_exist=True)
    except PageNotFoundError:
        print(f"No RfD page for {page_title}.")
        logging_.log_local(page_title, "no_rfd_logpage.txt")
        _onwiki_logger.log(_Messages.RFD0, page_title, now, rfd=rfd_title)
        return False

    # What idiot made this line necessary by building quotation-mark escaping
    # into {{rfd2}}?  Oh right.  Me.
    anchor = page_title.replace('"', "&quot;").removeprefix(":")
    parsed = mwph.parse(rfd.text)
    filed: Union[list[Tag], list[Heading]] = (
        parsed.filter_headings(
            matches=lambda heading: _compress_ws(heading.title) == anchor
        )
        or parsed.filter_tags(
            matches=lambda tag: _is_correct_anchor(tag, anchor)
        )
    )
    transcluders = [i.title() for i in rfd.embeddedin()]

    if not filed:
        print(f"RfD not filed for {page_title}.")
        logging_.log_local(page_title, "rfd_not_filed.txt")
        if now - page.editTime() > dt.timedelta(minutes=30):
            _onwiki_logger.log(_Messages.RFD1, page_title, now, rfd=rfd_title)
    elif "Wikipedia:Redirects for discussion" not in transcluders:
        print(f"{rfd_title} not transcluded to main RfD page.")
        logging_.log_local(page_title, "rfd_log_not_transcluded.txt")
        _onwiki_logger.log(_Messages.RFD2, page_title, now, rfd=rfd_title)
        return False
    return filed


def _extract_rfd(page: Page) -> Title:
    """Get the title of the log page referenced by an RfD tag.

    Uses the standard RfD log format and the `year`, `month`, and `day`
    parameters in {{subst:rfd}}.  This accounts for RfDs filed to
    previous dates.

    Arg:
      page:  A Page corresponding to a wikipage tagged with
        {{subst:rfd}}.

    Returns:
      A Title for an RfD log page, without guarantee that the page exists.
    """
    # Ugly hack around <https://github.com/earwig/mwparserfromhell/issues/251>.
    text = page.text.replace("<includeonly>safesubst:</includeonly>", "")
    parsed = mwph.parse(text)
    template = parsed.filter_templates()[0]
    year, month, day = (template.get(s).value.strip()
                        for s in ("year", "month", "day"))
    return Title(Namespace.PROJECT,
                 f"Redirects for discussion/Log/{year} {month} {day}")


def _is_correct_anchor(tag: Tag, target: str) -> bool:
    if tag.tag != 'span':
        return False
    try:
        # `strip('"')` could obscure HTML errors
        id_ = (tag.get('id').split("=", maxsplit=1)[1]
               .removeprefix('"').removesuffix('"'))
    except ValueError:  # If span has no id.
        return False
    return _compress_ws(id_) == target


def _compress_ws(text: str) -> str:
    return " ".join(text.split())


def cleanup(unreviewed_titles: list[str]) -> None:
    """Remove old and resolved log entries.

    Returns:
      A bool indicating whether cleanup occurred.
    """
    with _onwiki_logger.edit("Removing old and/or reviewed entries.") as data:
        for day, entries in data.copy().items():
            if _onwiki_logger.day_too_old(day):
                del data[day]
            else:
                entries = SensitiveList(
                    [i for i in entries
                     if i['page'].removeprefix(":") in unreviewed_titles]
                )
                if not entries:
                    del data[day]
                else:
                    data[day] = entries
        if data.been_changed():
            print("Cleaning up skippedRfDs.json")
